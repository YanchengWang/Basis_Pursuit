{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data matrix X with shape: (50, 10000)\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "rho = 10  # ρ\n",
    "d = 10  # Dimensionality of the subspace\n",
    "n = 50  # Ambient space dimensionality\n",
    "L = 100  # Number of subspaces\n",
    "Nl = rho * d  # Number of points per subspace\n",
    "N = L * Nl  # Total number of points\n",
    "\n",
    "\n",
    "def gram_schmidt(vectors):\n",
    "    num_vectors = vectors.shape[0]\n",
    "    orthogonalized_vectors = np.zeros_like(vectors, dtype=np.float64)\n",
    "\n",
    "    for i in range(num_vectors):\n",
    "        # Start with the original vector\n",
    "        vec = vectors[i].copy()\n",
    "        for j in range(i):\n",
    "            # Subtract the projection onto each previously orthogonalized vector\n",
    "            proj = np.dot(orthogonalized_vectors[j], vec) / np.dot(orthogonalized_vectors[j], orthogonalized_vectors[j])\n",
    "            vec -= proj * orthogonalized_vectors[j]\n",
    "        # Store the orthogonalized vector\n",
    "        orthogonalized_vectors[i] = vec\n",
    "\n",
    "    # Normalize vectors and handle zero-norm cases\n",
    "    for i in range(num_vectors):\n",
    "        norm = np.linalg.norm(orthogonalized_vectors[i])\n",
    "        if norm > 0:\n",
    "            orthogonalized_vectors[i] /= norm\n",
    "\n",
    "    return orthogonalized_vectors\n",
    "\n",
    "X = []\n",
    "# Loop through each subspace\n",
    "start_index = 0\n",
    "for l in range(L):\n",
    "    # Sample a Gaussian matrix A and obtain U using Schmidt orthogonalization\n",
    "    A = np.random.randn(n, d)\n",
    "    # U, _ = np.linalg.qr(A)  # U is orthogonal\n",
    "    U = gram_schmidt(A)\n",
    "    # Sample a Gaussian matrix B and normalize columns to lie on the unit sphere\n",
    "    B = np.random.randn(d, Nl)\n",
    "    B = B / np.linalg.norm(B, axis=0, keepdims=True)  # Normalize columns\n",
    "    \n",
    "    # Construct data for the l-th subspace\n",
    "    X_l = U @ B\n",
    "    \n",
    "    # Insert X_l into the global data matrix\n",
    "    end_index = start_index + Nl\n",
    "    # X[:, start_index:end_index] = X_l\n",
    "    start_index = end_index\n",
    "    X.append(X_l)\n",
    "\n",
    "X = np.concatenate(X, axis=1)\n",
    "print(\"Generated data matrix X with shape:\", X.shape)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum support size: 11\n",
      "Maximum support size: 75\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylops\n",
    "import pyproximal\n",
    "\n",
    "# Parameters\n",
    "epsilon = 1e-5\n",
    "threshold = 0.0005 # For calculating support size\n",
    "support_sizes = []\n",
    "\n",
    "# Loop through each column of X\n",
    "for i in range(10):\n",
    "    # Remove the i-th column from X to get X(-i)\n",
    "    X_minus_i = np.delete(X, i, axis=1)\n",
    "    X_i = X[:, i]\n",
    "\n",
    "    # Operator\n",
    "    Aop = pylops.MatrixMult(X_minus_i)\n",
    "    Aop.explicit = False  # Temporary solution whilst PyLops gets updated\n",
    "\n",
    "    # Observed data\n",
    "    y = X_i\n",
    "\n",
    "    # Define the optimization problem\n",
    "    f = pyproximal.AffineSet(Aop, y, niter=20)  # Constraint ||X_i - X_minus_i @ β||_2 <= epsilon\n",
    "    g = pyproximal.L1()  # Regularization term ||β||_1\n",
    "\n",
    "    # Solve the optimization problem using ADMM\n",
    "    beta_early = pyproximal.optimization.primal.ADMM(f, g, np.zeros(X_minus_i.shape[1]), 0.1, niter=10, show=False)[0]\n",
    "    beta = pyproximal.optimization.primal.ADMM(f, g, np.zeros(X_minus_i.shape[1]), 0.1, niter=150, show=False)[0]\n",
    "\n",
    "    # Calculate the support size for the final solution\n",
    "    support_size = np.sum(np.abs(beta) > threshold)\n",
    "    support_sizes.append(support_size)\n",
    "\n",
    "# Output the minimum and maximum support sizes\n",
    "print(\"Minimum support size:\", min(support_sizes))\n",
    "print(\"Maximum support size:\", max(support_sizes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprobust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
